{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5d4b6a-fee2-49c1-b0dd-aae44b015152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/css/tabulator_simple.min.css?v=1.5.5\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='99d6b0b4-439f-46e2-8773-d11e56da6523'>\n",
       "  <div id=\"e378bb4c-fa3b-4484-a7be-72aa728c0bc6\" data-root-id=\"99d6b0b4-439f-46e2-8773-d11e56da6523\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"042a905f-da5a-4b81-a45d-c7ef7bd22337\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"99d6b0b4-439f-46e2-8773-d11e56da6523\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"6349c624-0945-43ff-bb3a-7e7a8204d5bc\",\"attributes\":{\"plot_id\":\"99d6b0b4-439f-46e2-8773-d11e56da6523\",\"comm_id\":\"b2cc7cc3774a4e70a53b082fbb4f80ba\",\"client_comm_id\":\"13a5da552efc4751846b21c3d4e35544\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"042a905f-da5a-4b81-a45d-c7ef7bd22337\",\"roots\":{\"99d6b0b4-439f-46e2-8773-d11e56da6523\":\"e378bb4c-fa3b-4484-a7be-72aa728c0bc6\"},\"root_ids\":[\"99d6b0b4-439f-46e2-8773-d11e56da6523\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "99d6b0b4-439f-46e2-8773-d11e56da6523"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef25def69fd47e8bb68e68ef62e2646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pathway as pw\n",
    "import io\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "SERVICE_ACCOUNT_FILE = 'credentials.json'\n",
    "\n",
    "# Unknown Data\n",
    "\n",
    "table_papers = pw.io.gdrive.read(\n",
    "    object_id=\"1Y2Y0EsMalo26KcJiPYcAXh6UzgMNjh4u\",\n",
    "    mode=\"static\", \n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=True \n",
    ")\n",
    "\n",
    "# Known Data\n",
    "\n",
    "table_np = pw.io.gdrive.read(\n",
    "    object_id=\"1_xFmMlrNDR0wzzPsv6wXXdGz0eX6vaYb\",\n",
    "    mode=\"static\",\n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=False\n",
    ")\n",
    "\n",
    "CVPR = pw.io.gdrive.read(\n",
    "    object_id=\"1RifJJBjm5tA8E20808RjvkIAiWnFbceb\",\n",
    "    mode=\"static\",\n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=False\n",
    ")\n",
    "EMNLP = pw.io.gdrive.read(\n",
    "    object_id=\"1JVzabziJf4d2drCTXFssFr_wZMnjr8oT\",\n",
    "    mode=\"static\",\n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=False\n",
    ")\n",
    "KDD = pw.io.gdrive.read(\n",
    "    object_id=\"1sJKv0o5ySrigZewU_wtTxysx9j0kO_nV\",\n",
    "    mode=\"static\",\n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=False\n",
    ")\n",
    "NeurIPS = pw.io.gdrive.read(\n",
    "    object_id=\"1ZgkbpvhoNKUuH0b4uCv30lyWg3-5ijTC\",\n",
    "    mode=\"static\",\n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=False\n",
    ")\n",
    "TMLR = pw.io.gdrive.read(\n",
    "    object_id=\"13eDgt0YghQU2qlogGrTrXJzfD0h0F2Iw\",\n",
    "    mode=\"static\",\n",
    "    service_user_credentials_file=SERVICE_ACCOUNT_FILE,\n",
    "    with_metadata=False\n",
    ")\n",
    "\n",
    "def extract_text_from_pdf(pdf_bytes):\n",
    "    pdf_file = io.BytesIO(pdf_bytes)\n",
    "    reader = PdfReader(pdf_file) \n",
    "    text = \"\" \n",
    "    for page in reader.pages: \n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "tt_papers = table_papers.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, table_papers.data),\n",
    "    metadata=table_papers._metadata\n",
    ")\n",
    "\n",
    "tt_np = table_np.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, table_np.data), \n",
    ")\n",
    "\n",
    "tt_CVPR = CVPR.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, CVPR.data),\n",
    ")\n",
    "tt_EMNLP = EMNLP.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, EMNLP.data), \n",
    ")\n",
    "tt_KDD = KDD.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, KDD.data),\n",
    ")\n",
    "tt_NeurIPS = NeurIPS.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, NeurIPS.data), \n",
    ")\n",
    "tt_TMLR = TMLR.select(\n",
    "    pdf_text=pw.apply(extract_text_from_pdf, TMLR.data),\n",
    ")\n",
    "\n",
    "pw.io.csv.write(tt_papers, 'papers.csv')\n",
    "\n",
    "pw.io.csv.write(tt_np, 'ttnp.csv')\n",
    "\n",
    "pw.io.csv.write(tt_CVPR, 'CVPR.csv')\n",
    "pw.io.csv.write(tt_EMNLP, 'EMNLP.csv')\n",
    "pw.io.csv.write(tt_KDD, 'KDD.csv')\n",
    "pw.io.csv.write(tt_NeurIPS, 'NeurIPS.csv')\n",
    "pw.io.csv.write(tt_TMLR, 'TMLR.csv')\n",
    "\n",
    "pw.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ad5536-d407-48b9-ba62-288a585e6738",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10640a74-0096-4936-b44f-4498fc3741ef",
   "metadata": {},
   "source": [
    "## Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad57bb6-ca39-4e89-9ea5-c269fcfaa946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a2b107-5249-44d3-b1d1-2aa6432745c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('papers.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "sample_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb619016-887d-49b1-a5f5-1f3fc9bcd8d7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26647871-c7c8-49b4-a039-3eb654e9bd85",
   "metadata": {},
   "source": [
    "## Non-Publishable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fa875c-fa43-4389-b387-10be4021d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('ttnp.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "np_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2604c34-0f61-4075-b8ee-252c7a9d11da",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235b4cfc-f892-46cd-80c5-8918e0449bf2",
   "metadata": {},
   "source": [
    "## Publishable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba01a60-417d-48e8-ab5d-7cfc4528f710",
   "metadata": {},
   "source": [
    "### CVPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa72efa6-8102-4ccb-932f-50c714040371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('CVPR.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "cvpr_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1822f-3688-4b10-b2b8-9a6bfd254476",
   "metadata": {},
   "source": [
    "### EMNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db201c0b-ad12-4655-91d0-153cf5f095c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('EMNLP.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "emnlp_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622228f-268b-4079-944f-87678cc79a23",
   "metadata": {},
   "source": [
    "### KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71cae0a-35ef-422c-81b9-ee308c09ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('KDD.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "kdd_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f04fc-8a78-45bb-8ad5-64d1969eb978",
   "metadata": {},
   "source": [
    "### NeurIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16741eb3-4681-45cd-9adc-f330af7dbcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('NeurIPS.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "neurips_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6752210-315c-4ba2-815a-5e6386bcc511",
   "metadata": {},
   "source": [
    "### TMLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f027c65e-6647-4474-b05c-9eafbda8e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('TMLR.csv', mode='r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    data = list(csv_reader)\n",
    "\n",
    "import pandas as pd\n",
    "ttt1 = pd.DataFrame(data)\n",
    "\n",
    "ttt1['concatenated'] = ttt1.apply(\n",
    "    lambda row: ' '.join(\n",
    "        str(val) for val in row \n",
    "        if val not in ['None', ' None', 'None ']\n",
    "    ), axis=1\n",
    ").apply(lambda x: ' '.join(x.split()[:x.split().index('None')] if 'None' in x.split() else x.split()))\n",
    "\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "ttt1['concatenated'] = ttt1['concatenated'].apply(lambda x: x.replace('\\\\n', ' '))\n",
    "lt1 = list(ttt1['concatenated'])\n",
    "del lt1[0]\n",
    "tmlr_list = [e.rsplit(' ', 3)[0] for e in lt1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a5ce7e-fd31-41f3-a9bf-2d682f0e5978",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf39124-e683-4553-81ae-2618b8c7774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "npub_files = np_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c0f98-b0e0-4947-bb14-74b06f9cde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_files = {'CVPR':cvpr_list,'EMNLP':emnlp_list,'KDD':kdd_list,'NeurIPS':neurips_list,'TMLR':tmlr_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6bfbc4-7e06-4aa4-a7b4-69eaf1e659a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVC  # Changed to SVM\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db2ea3-569c-4441-9572-4a83ad3e8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Preprocess text by removing special characters, digits, stopwords, and converting to lowercase.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c773a-8062-44fe-92e8-302da84c1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(preprocessed_text):\n",
    "    \"\"\"Extract features from preprocessed text.\"\"\"\n",
    "    features = {}\n",
    "    words = preprocessed_text.split()\n",
    "    features['word_count'] = len(words)\n",
    "    features['unique_words'] = len(set(words))\n",
    "    features['lexical_diversity'] = features['unique_words'] / features['word_count'] if features['word_count'] > 0 else 0\n",
    "    features['reference_count'] = len(re.findall(r'\\[\\d+\\]|\\(\\d{4}\\)', preprocessed_text))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332940ba-221e-435a-8aa4-c6f065489119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_rationale(features, confidence):\n",
    "    \"\"\"Generate a rationale for a paper's classification.\"\"\"\n",
    "    rationale = []\n",
    "\n",
    "    if features['word_count'] > 7000:\n",
    "        rationale.append(\"High word count may indicate verbosity.\")\n",
    "    elif features['word_count'] < 1500:\n",
    "        rationale.append(\"Concise presentation.\")\n",
    "\n",
    "    if features['lexical_diversity'] > 0.4:\n",
    "        rationale.append(\"Good vocabulary diversity.\")\n",
    "    elif features['lexical_diversity'] < 0.25:\n",
    "        rationale.append(\"Limited vocabulary range.\")\n",
    "\n",
    "    if features['reference_count'] > 10:\n",
    "        rationale.append(\"Well-referenced.\")\n",
    "    elif features['reference_count'] < 2:\n",
    "        rationale.append(\"Limited citations.\")\n",
    "\n",
    "    if confidence > 0.85:\n",
    "        rationale.append(\"Strong classifier confidence.\")\n",
    "    elif confidence < 0.6:\n",
    "        rationale.append(\"Borderline classification.\")\n",
    "\n",
    "    return \" \".join(rationale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075c27c-d70d-4786-9887-cdf01dd36a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def takename(string):\n",
    "    match = re.search(r'name:\"(.*?)\"', string)\n",
    "    if match:\n",
    "        return (match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fbc7b9-a288-465f-9927-aa25081a829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_clear(string):\n",
    "    cleaned_text = re.sub(r'{\"mimeType\":\".*', '', string, flags=re.DOTALL)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897337c8-c284-4a65-903e-25058f1e6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading and preprocessing papers...\")\n",
    "papers_data = []\n",
    "for f in sample_list:\n",
    "    string = f\n",
    "    if string:\n",
    "        filename = takename(string)\n",
    "        cleaned_string = take_clear(string)\n",
    "        processed_text = preprocess_text(cleaned_string)\n",
    "        features = extract_features(processed_text)\n",
    "        papers_data.append({'text': processed_text, 'features': features, 'filename': filename})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee666be9-9e21-4509-bb5a-dce339918f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_data, ref_labels, ref_conferences = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1ec400-3bed-4647-9c14-5c32ca569272",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in np_list:\n",
    "    content = f\n",
    "    if content:\n",
    "        processed_text = preprocess_text(content)\n",
    "        features = extract_features(processed_text)\n",
    "        ref_data.append({'text': processed_text, 'features': features})\n",
    "        ref_labels.append(0)\n",
    "        ref_conferences.append(\"na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0844ab-79c7-4364-a603-e35970d4e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conf, files in pub_files.items():\n",
    "    for f in files:\n",
    "        content = f\n",
    "        if content:\n",
    "            processed_text = preprocess_text(content)\n",
    "            features = extract_features(processed_text)\n",
    "            ref_data.append({'text': processed_text, 'features': features})\n",
    "            ref_labels.append(1)\n",
    "            ref_conferences.append(conf.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713ac2f2-9509-4f8c-bc22-a5cb4004216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating features...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_ref_text = vectorizer.fit_transform([d['text'] for d in ref_data])\n",
    "X_ref_features = pd.DataFrame([d['features'] for d in ref_data])\n",
    "X_reference = np.hstack([X_ref_text.toarray(), X_ref_features])\n",
    "\n",
    "X_papers_text = vectorizer.transform([d['text'] for d in papers_data])\n",
    "X_papers_features = pd.DataFrame([d['features'] for d in papers_data])\n",
    "X_papers = np.hstack([X_papers_text.toarray(), X_papers_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4aa5f3-e862-442c-aab5-1eb9562a213e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_classes, class_counts = np.unique(ref_labels, return_counts=True)\n",
    "print(\"\\nClass distribution for publishable/non-publishable:\")\n",
    "for cls, count in zip(unique_classes, class_counts):\n",
    "    print(f\"Class {cls}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba473e6-2832-4287-982e-0cea630da069",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming hyperparameter tuning for SVM...\")\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
    "    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient for 'rbf' and 'poly'\n",
    "    'degree': [2, 3, 4]  # Degree of the polynomial kernel (only for 'poly')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c675b3b-16fb-46da-882d-d3713b319dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_strategy = StratifiedKFold(n_splits=min(3, min(class_counts)))  # Ensure n_splits <= smallest class count\n",
    "grid_search = GridSearchCV(estimator=SVC(probability=True, random_state=42), param_grid=param_grid, cv=cv_strategy, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_reference, ref_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da76668c-224b-47de-92d9-75c2d315c966",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(f\"\\nBest Hyperparameters for Publishable/Non-Publishable Classifier: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8694d9fc-f987-44b7-ba00-bd1e1d05fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_clf = SVC(probability=True, random_state=42, **best_params)\n",
    "best_clf.fit(X_reference, ref_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04d797-c3ad-4a3c-ab71-db9aa5b4d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_clf.predict(X_reference)\n",
    "accuracy = accuracy_score(ref_labels, y_pred_train)\n",
    "print(f\"Accuracy of Publishable/Non-Publishable Classifier: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77bed7-77a2-4482-93f9-5416857e67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_predictions = best_clf.predict(X_papers)\n",
    "paper_probabilities = best_clf.predict_proba(X_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d801136-c359-4c73-af0d-1a25490eb3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "conf_data = [d['text'] for i, d in enumerate(ref_data) if ref_labels[i] == 1]\n",
    "conf_labels = [c for i, c in enumerate(ref_conferences) if ref_labels[i] == 1]\n",
    "X_conf = conf_vectorizer.fit_transform(conf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78e981c-5341-46ab-a019-5547bb244568",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "conf_labels_encoded = label_encoder.fit_transform(conf_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd51ae-2f01-4b9a-8c2f-2008764258fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_confs, conf_counts = np.unique(conf_labels_encoded, return_counts=True)\n",
    "print(\"\\nClass distribution for conferences:\")\n",
    "for conf, count in zip(unique_confs, conf_counts):\n",
    "    print(f\"Conference {conf}: {count} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c6b04e-6d9d-43ff-ae51-6f7e6e523ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPerforming hyperparameter tuning for Conference Classifier...\")\n",
    "conf_cv_strategy = StratifiedKFold(n_splits=min(3, min(conf_counts)))  # Ensure n_splits <= smallest class count\n",
    "conf_grid_search = GridSearchCV(estimator=SVC(probability=True, random_state=42), param_grid=param_grid, cv=conf_cv_strategy, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "conf_grid_search.fit(X_conf, conf_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9c6be-7b96-401d-9d96-96ff45c54278",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_conf_params = conf_grid_search.best_params_\n",
    "print(f\"\\nBest Hyperparameters for Conference Classifier: {best_conf_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3d7424-6c55-4841-bb21-55681529e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_conf_clf = SVC(probability=True, random_state=42, **best_conf_params)\n",
    "best_conf_clf.fit(X_conf, conf_labels_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b290977-b793-43a2-9de1-6b0fe9f47521",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_conf_pred_train = best_conf_clf.predict(X_conf)\n",
    "conf_accuracy = accuracy_score(conf_labels_encoded, y_conf_pred_train)\n",
    "print(f\"Accuracy of Conference Classifier: {conf_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096328ce-0767-434c-8a7e-e23736b76144",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for i, (pred, probs) in enumerate(zip(paper_predictions, paper_probabilities)):\n",
    "    paper_id = f\"P{str(i + 1).zfill(3)}\"\n",
    "    confidence = max(probs)\n",
    "\n",
    "    if pred == 1:\n",
    "        paper_text = papers_data[i]['text']\n",
    "        conf_pred = best_conf_clf.predict(conf_vectorizer.transform([paper_text]))\n",
    "        conference = label_encoder.inverse_transform(conf_pred)[0]\n",
    "    else:\n",
    "        conference = \"na\"\n",
    "\n",
    "    rationale = generate_rationale(papers_data[i]['features'], confidence)\n",
    "\n",
    "    results.append({\n",
    "        'Paper ID': paper_id,\n",
    "        'Publishable': int(pred),\n",
    "        'Conference': conference,\n",
    "        'Rationale': rationale\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fd6691-ec2e-4972-b5a3-8f4da5bd2cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "publishable_count = 0\n",
    "non_publishable_count = 0\n",
    "conference_counts = {}\n",
    "\n",
    "for result in results:\n",
    "    if result['Conference'] == \"na\":\n",
    "        non_publishable_count += 1\n",
    "    else:\n",
    "        publishable_count += 1\n",
    "        conference = result['Conference']\n",
    "        if conference not in conference_counts:\n",
    "            conference_counts[conference] = 0\n",
    "        conference_counts[conference] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68746d7b-b58d-4e7f-babd-6b2e36ab31cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nPublishable papers: {publishable_count}\")\n",
    "print(f\"Non-publishable papers: {non_publishable_count}\")\n",
    "print(\"\\nConference-wise publishable paper count:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d19445-954d-41fc-a067-ee190647a296",
   "metadata": {},
   "outputs": [],
   "source": [
    "for conference, count in conference_counts.items():\n",
    "    print(f\"{conference}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7fc64-dbc9-46a5-9d11-ad054de1a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('output.csv', index=False)\n",
    "print(\"\\nResults have been saved to 'output.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245aff98-a148-4a9f-aec7-cd7f67003bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
